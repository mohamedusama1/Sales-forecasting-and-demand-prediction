{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271dd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8000\n",
      " * Running on http://192.168.1.113:8000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [11/May/2025 21:52:17] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ─── 0) Load all your static assets ───────────────────────────────────────────────\n",
    "stores       = pd.read_csv('stores.csv')\n",
    "transactions = pd.read_csv('transactions.csv', parse_dates=['date'])\n",
    "oil          = pd.read_csv('oil.csv',      parse_dates=['date'])\n",
    "holidays     = pd.read_csv('holidays_events.csv')\n",
    "\n",
    "MODEL        = lgb.Booster(model_file='lgb_model.txt')\n",
    "\n",
    "with open('feature_columns.json','r') as f:\n",
    "    EXPECTED_COLS = json.load(f)\n",
    "\n",
    "# Dedupe your saved schema (just in case)\n",
    "seen = set(); deduped = []\n",
    "for c in EXPECTED_COLS:\n",
    "    if c not in seen:\n",
    "        deduped.append(c); seen.add(c)\n",
    "EXPECTED_COLS = deduped\n",
    "\n",
    "\n",
    "# ─── 1) Feature‐engineering Helpers ──────────────────────────────────────────────\n",
    "\n",
    "def create_date_features(df):\n",
    "    df['month']            = df.date.dt.month.astype('int8')\n",
    "    df['day_of_month']     = df.date.dt.day.astype('int8')\n",
    "    df['day_of_year']      = df.date.dt.dayofyear.astype('int16')\n",
    "    df['week_of_month']    = ((df.date.dt.day - 1)//7 + 1).astype('int8')\n",
    "    df['week_of_year']     = df.date.dt.isocalendar().week.astype('int8')\n",
    "    df['day_of_week']      = (df.date.dt.dayofweek + 1).astype('int8')\n",
    "    df['year']             = df.date.dt.year.astype('int32')\n",
    "    df['is_wknd']          = (df.date.dt.weekday//4).astype('int8')\n",
    "    df['quarter']          = df.date.dt.quarter.astype('int8')\n",
    "    df['is_month_start']   = df.date.dt.is_month_start.astype('int8')\n",
    "    df['is_month_end']     = df.date.dt.is_month_end.astype('int8')\n",
    "    df['is_quarter_start'] = df.date.dt.is_quarter_start.astype('int8')\n",
    "    df['is_quarter_end']   = df.date.dt.is_quarter_end.astype('int8')\n",
    "    df['is_year_start']    = df.date.dt.is_year_start.astype('int8')\n",
    "    df['is_year_end']      = df.date.dt.is_year_end.astype('int8')\n",
    "    df['season'] = np.where(\n",
    "        df.month.isin([12,1,2]), 0,\n",
    "        np.where(df.month.isin([6,7,8]), 2,\n",
    "                 np.where(df.month.isin([9,10,11]), 3, 1))\n",
    "    ).astype('int8')\n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    original = list(df.columns)\n",
    "    cats     = df.select_dtypes(['object','category']).columns.tolist()\n",
    "    df_enc   = pd.get_dummies(df, columns=cats, dummy_na=nan_as_category)\n",
    "    df_enc.columns = df_enc.columns.str.replace(' ', '_')\n",
    "    return df_enc, [c for c in df_enc.columns if c not in original]\n",
    "\n",
    "def create_oil_features(df, oil):\n",
    "    if not pd.api.types.is_datetime64_dtype(oil['date']):\n",
    "        oil['date'] = pd.to_datetime(oil['date'])\n",
    "    oil_series = (\n",
    "        oil.set_index('date')['dcoilwtico']\n",
    "           .replace(0, np.nan)\n",
    "           .interpolate()\n",
    "           .fillna(method='bfill')\n",
    "           .rename('dcoilwtico_interpolated')\n",
    "           .reset_index()\n",
    "    )\n",
    "    df = df.merge(oil_series, on='date', how='left')\n",
    "    df['oil_above_70'] = (df.dcoilwtico_interpolated >= 70).astype('int8')\n",
    "    df.drop('dcoilwtico_interpolated', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def create_holiday_features(df, holidays):\n",
    "    # copy & immediately drop 'transferred' so holidays.columns stay fixed\n",
    "    h = holidays.copy().drop('transferred', axis=1)\n",
    "    h[\"date\"]        = pd.to_datetime(h.date)\n",
    "    h['description'] = h.description.fillna('').astype(str)\n",
    "\n",
    "    # 1) build transferred-tr1/tr2\n",
    "    tr1 = h[(h.type==\"Holiday\")][['date','description','type','locale','locale_name']]\n",
    "    tr2 = h[(h.type==\"Transfer\")][['date','description','type','locale','locale_name']]\n",
    "    if not tr1.empty and not tr2.empty:\n",
    "        tr = pd.concat([tr1.reset_index(drop=True), tr2.reset_index(drop=True)], axis=1)\n",
    "        tr = tr.iloc[:, :5]                # keep only 5 core columns\n",
    "        tr.columns = ['date','description','type','locale','locale_name']\n",
    "    else:\n",
    "        tr = pd.DataFrame(columns=['date','description','type','locale','locale_name'])\n",
    "\n",
    "    # 2) base holidays (exclude Transfer)\n",
    "    base = h[h.type!=\"Transfer\"].drop_duplicates()\n",
    "\n",
    "    # 3) stack rows\n",
    "    holidays_full = pd.concat([base, tr], axis=0, ignore_index=True)\n",
    "\n",
    "    # 4) clean-up\n",
    "    holidays_full[\"description\"] = holidays_full.description.str.replace(r\"[-\\d+]\",\"\",regex=True)\n",
    "    holidays_full[\"type\"]        = np.where(\n",
    "        holidays_full.type==\"Additional\",\"Holiday\",holidays_full.type)\n",
    "    holidays_full[\"description\"] = holidays_full.description.str.replace(\"Puente \",\"\",regex=False)\n",
    "    holidays_full[\"type\"]        = np.where(\n",
    "        holidays_full.type==\"Bridge\",\"Holiday\",holidays_full.type)\n",
    "\n",
    "    # 5) split work_day / events\n",
    "    work_day  = holidays_full[holidays_full.type==\"Work Day\"]\n",
    "    evt_table = holidays_full[holidays_full.type!=\"Work Day\"]\n",
    "\n",
    "    events = (evt_table[evt_table.type==\"Event\"]\n",
    "              .drop(['type','locale','locale_name'],axis=1)\n",
    "              .rename({'description':'events'},axis=1))\n",
    "    hol_tbl = evt_table[evt_table.type!=\"Event\"].drop('type',axis=1)\n",
    "\n",
    "    # 6) merge national/regional/local\n",
    "    if not hol_tbl.empty:\n",
    "        regional = (hol_tbl[hol_tbl.locale==\"Regional\"]\n",
    "                    .rename({'locale_name':'state','description':'holiday_regional'},axis=1)\n",
    "                    .drop('locale',axis=1).drop_duplicates())\n",
    "        national = (hol_tbl[hol_tbl.locale==\"National\"]\n",
    "                    .rename({'description':'holiday_national'},axis=1)\n",
    "                    .drop(['locale','locale_name'],axis=1).drop_duplicates())\n",
    "        local    = (hol_tbl[hol_tbl.locale==\"Local\"]\n",
    "                    .rename({'description':'holiday_local','locale_name':'city'},axis=1)\n",
    "                    .drop('locale',axis=1).drop_duplicates())\n",
    "    else:\n",
    "        regional = pd.DataFrame(columns=[\"date\",\"state\",\"holiday_regional\"])\n",
    "        national = pd.DataFrame(columns=[\"date\",\"holiday_national\"])\n",
    "        local    = pd.DataFrame(columns=[\"date\",\"city\",\"holiday_local\"])\n",
    "\n",
    "    df = df.merge(national, how='left', on='date')\n",
    "    df = df.merge(regional, how='left', on=['date','state']) if 'state' in df else df.assign(holiday_regional=np.nan)\n",
    "    df = df.merge(local,    how='left', on=['date','city'])  if 'city'  in df else df.assign(holiday_local=np.nan)\n",
    "\n",
    "    # 7) work_day & events one‐hots\n",
    "    df = df.merge(work_day[['date','type']].rename({'type':'IsWorkDay'},axis=1),\n",
    "                  how='left') if not work_day.empty else df.assign(IsWorkDay=np.nan)\n",
    "    if 'events' in events.columns and not events.empty:\n",
    "        events['events'] = (events.events.fillna('').astype(str)\n",
    "                            .pipe(lambda s: np.where(s.str.contains('futbol',na=False),'Futbol',s)))\n",
    "        evt_enc, evt_cat = one_hot_encoder(events)\n",
    "        df = df.merge(evt_enc, how='left', on='date')\n",
    "        if evt_cat:\n",
    "            df[evt_cat] = df[evt_cat].fillna(0)\n",
    "\n",
    "    # 8) binary flags & local‐string flags\n",
    "    df['holiday_national_binary']  = df.holiday_national.notna().astype('int8')\n",
    "    df['holiday_local_binary']     = df.holiday_local.notna().astype('int8')\n",
    "    df['holiday_regional_binary']  = df.holiday_regional.notna().astype('int8')\n",
    "    df['national_independence']    = np.where(\n",
    "        df.holiday_national.isin([\n",
    "          'Batalla de Pichincha','Independencia de Cuenca',\n",
    "          'Independencia de Guayaquil','Primer Grito de Independencia'\n",
    "        ]),1,0).astype('int8')\n",
    "\n",
    "    df['holiday_local']        = df.holiday_local.fillna('').astype(str)\n",
    "    df['local_cantonizacio']   = np.where(df.holiday_local.str.contains('Cantonizacio',na=False),1,0).astype('int8')\n",
    "    df['local_fundacion']      = np.where(df.holiday_local.str.contains('Fundacion',na=False),1,0).astype('int8')\n",
    "    df['local_independencia']  = np.where(df.holiday_local.str.contains('Independencia',na=False),1,0).astype('int8')\n",
    "\n",
    "    # final one‐hot the holiday columns\n",
    "    hol_cols = [\"holiday_national\",\"holiday_regional\",\"holiday_local\"]\n",
    "    existing = [c for c in hol_cols if c in df]\n",
    "    if existing:\n",
    "        for c in existing:\n",
    "            df[c] = df[c].fillna('').astype(str)\n",
    "        hol_enc, hol_cat = one_hot_encoder(df[existing], nan_as_category=False)\n",
    "        df = pd.concat([df.drop(existing,axis=1), hol_enc], axis=1)\n",
    "\n",
    "    return df, work_day\n",
    "\n",
    "def preprocess_full(raw, stores, transactions, oil, holidays_df):\n",
    "    raw['date'] = pd.to_datetime(raw.date)\n",
    "    df = raw.merge(stores, on='store_nbr', how='left')\n",
    "    df, work_day = create_holiday_features(df, holidays_df)\n",
    "    df = create_date_features(df)\n",
    "    df = create_oil_features(df, oil)\n",
    "    df['workday'] = (~(\n",
    "        (df.holiday_national_binary==1) |\n",
    "        (df.holiday_regional_binary==1) |\n",
    "        (df.holiday_local_binary==1) |\n",
    "        (df.day_of_week.isin([6,7]))\n",
    "    )).astype('int8')\n",
    "    df.loc[df.date.isin(work_day.date), 'workday'] = 1\n",
    "    df['wageday'] = ((df.is_month_end==1)|(df.day_of_month==15)).astype('int8')\n",
    "    for c in ['family','city','state','type','cluster','oil_above_70']:\n",
    "        df[c] = df[c].astype('category') if c in df else df[c]\n",
    "    return df\n",
    "\n",
    "# ─── 2) The /predict endpoint ────────────────────────────────────────────────────\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    p = request.get_json()\n",
    "    raw = pd.DataFrame([{\n",
    "        'id':          p['id'],\n",
    "        'date':        p['date'],\n",
    "        'store_nbr':   p['store_nbr'],\n",
    "        'family':      p['family'],\n",
    "        'onpromotion': p['onpromotion']\n",
    "    }])\n",
    "    df_feat = preprocess_full(raw, stores, transactions, oil, holidays)\n",
    "    df_feat = df_feat.reindex(columns=EXPECTED_COLS, fill_value=0)\n",
    "\n",
    "    out_id   = int(df_feat['id'].iloc[0])\n",
    "    out_date = df_feat['date'].iloc[0]\n",
    "\n",
    "    X_pred = df_feat.drop(['id','date','sales'], axis=1, errors='ignore').copy()\n",
    "    for c in ['city','state','type','family','cluster','oil_above_70','IsWorkDay']:\n",
    "        if c in X_pred: X_pred[c] = X_pred[c].astype('category')\n",
    "\n",
    "    y_log1p = MODEL.predict(X_pred, validate_features=False)\n",
    "    y_pred   = float(np.expm1(y_log1p)[0])\n",
    "\n",
    "    return jsonify({\n",
    "        'id': out_id,\n",
    "        'date': str(out_date),\n",
    "        'predicted_sales': y_pred\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # disable the reloader inside notebooks\n",
    "    app.run(host='0.0.0.0', port=8000, debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b582998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sales array:\n",
      "[4.46368169]\n",
      "\n",
      "Detailed output:\n",
      "id: 3000888, date: 2017-08-16T00:00:00.000000000, predicted_sales: 4.46\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ─── assume x is your input DataFrame ───────────────────────\n",
    "# it looks like:\n",
    "#    id   date     store_nbr  family   sales  onpromotion  city  state  type  ...\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "\n",
    "# 1) Pull out id & date so we can print them later\n",
    "ids   = x['id'].values\n",
    "dates = x['date'].values\n",
    "\n",
    "# 2) Build the feature matrix for prediction\n",
    "X_pred = x.drop(['id', 'date', 'sales'], axis=1).copy()\n",
    "\n",
    "# 3) Cast your categoricals exactly like you did in training\n",
    "cat_cols = ['city','state','type','family','cluster','oil_above_70','IsWorkDay']\n",
    "for c in cat_cols:\n",
    "    if c in X_pred.columns:\n",
    "        X_pred[c] = X_pred[c].astype('category')\n",
    "\n",
    "# 4) Load your LightGBM model\n",
    "model = lgb.Booster(model_file='lgb_model.txt')\n",
    "\n",
    "# 5) Predict log1p(sales), skipping the pandas‐metadata check\n",
    "y_log1p = model.predict(X_pred, validate_features=False)\n",
    "\n",
    "# 6) Invert the transform\n",
    "y_pred = np.expm1(y_log1p)\n",
    "\n",
    "# 7a) Print the plain NumPy array of sales\n",
    "print(\"Predicted sales array:\")\n",
    "print(y_pred)\n",
    "\n",
    "# 7b) (Optional) Print them alongside id & date\n",
    "print(\"\\nDetailed output:\")\n",
    "for _id, _date, sale in zip(ids, dates, y_pred):\n",
    "    print(f\"id: {_id}, date: {_date}, predicted_sales: {sale:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
